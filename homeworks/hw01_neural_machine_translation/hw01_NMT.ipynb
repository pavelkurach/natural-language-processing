{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab assignment 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "\n",
    "path_do_data = \"../../datasets/Machine_translation_EN_RU/data.txt\"\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = \"./data.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({\"figure.figsize\": (16, 12), \"font.size\": 14})\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data, format=\"tsv\", fields=[(\"trg\", TRG), (\"src\", SRC)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=3)\n",
    "TRG.build_vocab(train_data, min_freq=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9280\n",
      "Unique tokens in target (en) vocabulary: 6724\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'sea',\n",
       " 'tower',\n",
       " 'каменном',\n",
       " 'bird',\n",
       " 'яркие',\n",
       " 'lan',\n",
       " 'фруктовые',\n",
       " 'денпасара',\n",
       " 'сушки']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'tastefully', 'closet', 'douro', 'milas', 'singapore', 'mani']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['guests', 'of', 'pension', 'neumayr', 'can', 'use', 'a', 'sauna', ',', 'infrared', 'cabin', 'and', 'sun', 'terrace', 'with', 'deckchairs', 'free', 'of', 'charge', '.'], 'src': ['в', 'гостевом', 'доме', 'neumayr', 'гости', 'могут', 'бесплатно', 'посещать', 'сауну', 'и', 'пользоваться', 'инфракрасной', 'кабиной', 'и', 'солнечной', 'террасой', 'с', 'шезлонгами', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)[\"src\"] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)[\"trg\"] for x in train_data.examples])\n",
    "\n",
    "print(\"Length distribution in Train data\")\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \n",
    "                      \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key=_len_sort_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.trg]:[torch.mps.LongTensor of size 46x128]\n",
      "\t[.src]:[torch.mps.LongTensor of size 36x128]\n",
      "torch.Size([36, 128]) torch.Size([46, 128])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "\n",
    "Transformer = my_network.Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.98 GB, other allocations: 111.45 MB, max allowed: 9.07 GB). Tried to allocate 6.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m MAX_LEN \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m SRC_PAD_IDX \u001b[39m=\u001b[39m SRC\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstoi[\u001b[39m\"\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m Transformer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     d_model \u001b[39m=\u001b[39;49m D_MODEL,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         src_vocab_size \u001b[39m=\u001b[39;49m SRC_VOCAB_SIZE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         trg_vocab_size \u001b[39m=\u001b[39;49m TRG_VOCAB_SIZE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         src_pad_idx \u001b[39m=\u001b[39;49m SRC_PAD_IDX,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         n_heads \u001b[39m=\u001b[39;49m N_HEADS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         num_encoder_layers \u001b[39m=\u001b[39;49m NUM_ENCODER_LAYERS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         num_decoder_layers \u001b[39m=\u001b[39;49m NUM_DECODER_LAYERS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         dim_feedforward \u001b[39m=\u001b[39;49m DIM_FEEDFORWARD,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         dropout \u001b[39m=\u001b[39;49m DROPOUT,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         max_len \u001b[39m=\u001b[39;49m MAX_LEN,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         device \u001b[39m=\u001b[39;49m device,\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m )\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.98 GB, other allocations: 111.45 MB, max allowed: 9.07 GB). Tried to allocate 6.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE = len(SRC.vocab)\n",
    "TRG_VOCAB_SIZE = len(TRG.vocab)\n",
    "D_MODEL = 264\n",
    "N_HEADS = 4\n",
    "NUM_ENCODER_LAYERS = 4\n",
    "NUM_DECODER_LAYERS = 4\n",
    "DIM_FEEDFORWARD=512\n",
    "DROPOUT=0.2\n",
    "MAX_LEN = 1000\n",
    "\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "model = Transformer(\n",
    "    d_model = D_MODEL,\n",
    "        src_vocab_size = SRC_VOCAB_SIZE,\n",
    "        trg_vocab_size = TRG_VOCAB_SIZE,\n",
    "        src_pad_idx = SRC_PAD_IDX,\n",
    "        n_heads = N_HEADS,\n",
    "        num_encoder_layers = NUM_ENCODER_LAYERS,\n",
    "        num_decoder_layers = NUM_DECODER_LAYERS,\n",
    "        dim_feedforward = DIM_FEEDFORWARD,\n",
    "        dropout = DROPOUT,\n",
    "        max_len = MAX_LEN,\n",
    "        device = device,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (src_word_embedding): Embedding(9280, 512)\n",
       "  (src_position_embedding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (trg_word_embedding): Embedding(6724, 512)\n",
       "  (trg_position_embedding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=512, out_features=6724, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for layer in m._modules:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 55,784,004 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = my_network.CosineWarmupScheduler(\n",
    "    optimizer=optimizer, \n",
    "    warmup=(40000 / (BATCH_SIZE * 10)), max_iters=(40000 / BATCH_SIZE)\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=SRC_PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None, epoch=1\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # output = [trg sent len, batch size, output dim]\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        # trg = [(trg sent len - 1) * batch size]\n",
    "        # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i + 1) % 10 == 0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label=\"train loss\")\n",
    "            ax[0].set_xlabel(\"Batch\")\n",
    "            ax[0].set_title(\"Train loss\")\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label=\"general train history\")\n",
    "                ax[1].set_xlabel(\"Epoch\")\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label=\"general valid history\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg)  # turn off teacher forcing\n",
    "\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # trg = [(trg sent len - 1) * batch size]\n",
    "            # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.93 GB, other allocations: 125.16 MB, max allowed: 9.07 GB). Tried to allocate 26.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, N_EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history, epoch\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trg \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtrg\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m model(src, trg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# trg = [trg sent len, batch size]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# output = [trg sent len, batch size, output dim]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m output \u001b[39m=\u001b[39m output[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:46\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src, trg):\n\u001b[1;32m     44\u001b[0m     trg_seq_length, _ \u001b[39m=\u001b[39m trg\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> 46\u001b[0m     embed_src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msrc_position_embedding(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msrc_word_embedding(src))\n\u001b[1;32m     47\u001b[0m     embed_trg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrg_position_embedding(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_word_embedding(trg))\n\u001b[1;32m     49\u001b[0m     src_padding_mask \u001b[39m=\u001b[39m (\n\u001b[1;32m     50\u001b[0m         (src\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_pad_idx)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     51\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:84\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     83\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpe[: x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)]\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.93 GB, other allocations: 125.16 MB, max allowed: 9.07 GB). Tried to allocate 26.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(\n",
    "        model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history, epoch\n",
    "    )\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"transformer-model.pt\")\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/qd_50t6125vb7v8pbdy0x1rh0000gn/T/ipykernel_80875/2475971412.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import imp\n",
    "\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the private bathroom comes with a shower .\n",
      "Generated: end a14 landmark 130 landmark landmark 130 greets greets a14 a14 a14 a14 a14 a14 a14\n",
      "\n",
      "Original: towels and bed linen are offered .\n",
      "Generated: pollença pollença città end pollença gregorio gregorio pollença pollença pollença pollença pollença pollença pollença gli gli\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1, 2]:\n",
    "    src = batch.src[:, idx : idx + 1]\n",
    "    trg = batch.trg[:, idx : idx + 1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [01:04,  7.22it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "#model.load_state_dict(torch.load(\"transformer-model.pt\"))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "\n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend(\n",
    "            [get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T]\n",
    "        )\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.74176357122177"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
