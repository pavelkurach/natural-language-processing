{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab assignment 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "\n",
    "path_do_data = \"../../datasets/Machine_translation_EN_RU/data.txt\"\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = \"./data.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({\"figure.figsize\": (16, 12), \"font.size\": 14})\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data, format=\"tsv\", fields=[(\"trg\", TRG), (\"src\", SRC)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=3)\n",
    "TRG.build_vocab(train_data, min_freq=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9249\n",
      "Unique tokens in target (en) vocabulary: 6720\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'сен',\n",
       " 'шереметьево',\n",
       " 'интернациональные',\n",
       " 'gite',\n",
       " 'alpen',\n",
       " 'pensjonat',\n",
       " 'фес',\n",
       " 'жалюзи',\n",
       " 'титизее']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'big', 'cream', 'cm', 'money', 'shiatsu', 'manzanillo']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['holiday', 'home', 'lærkedalen', 'ringkøbing', 'iv', 'is', 'located', 'in', 'søndervig', 'and', 'can', 'accommodate', 'up', 'to', 'five', 'persons', '.'], 'src': ['дом', 'для', 'отпуска', 'lærkedalen', 'ringkøbing', 'iv', 'расположен', 'в', 'городке', 'сёндервиг', 'и', 'подходит', 'для', 'размещения', 'до', '5', 'гостей', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAF/CAYAAACsbMTRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABWeklEQVR4nO3de1yUZd4/8M8oOMJwEE3TUQHlYKGirYoFKqKrlD5ruhnlup4SS3+ubtDGI8KCsCLCZqD5PGhgqLHqtj1GPSlCrRySVKIED6QOmockO62AHCSQ6/eHz9zLODPIIDDA/Xm/XrxecN3fe+5rhuHLl4vrvi6FEEKAiIiIiEiGepi7A0RERERE5sJimIiIiIhki8UwEREREckWi2EiIiIiki0Ww0REREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2WIxTERERESyxWKYqJ1NnToVCoUCu3fvNndX2l1OTg4UCgWcnZ3N3RUiamLp0qVQKBTYsGFDh163K+W/rtTXh8VcrcvC3B0goq6hqKgI6enpcHZ2xtKlS83dHaKHkpiYiPLycixdupQFQStpC+tXX30Vffr0MWtf6N+Yq03HkWEiapGioiJERUXJYtSEur/ExERERUXhypUr5u5KlxUVFYWoqCiUl5cbjXF0dMSIESNgb2/fcR2TOeZq03FkmIiIiNrF3r17zd0FogfiyDARERERyRaLYdJx+/ZtREdH44knnoCtrS2USiUGDx6MiRMn4vXXX0dpaaneOUII7N+/HzNmzEC/fv3Qq1cvDBkyBAsXLsSpU6cMXmfDhg1QKBTNzmdydnaGQqFATk6O0XPv3LmD6OhojBo1CiqVSm/e2o0bNxASEgJPT0/Y2tpCpVLB3d0dixYtQlZWlsHrnjlzBi+99BKGDx+O3r17o0+fPpg0aRJSUlJw9+7dZl+/1vjhhx8QGhoq9dHa2hqjRo1CREQEKioqDJ6jUCigUChw5coVnDlzBi+88AIeffRRKJVKjBgxAtHR0fjll1+MXvPLL7/Es88+i379+sHa2hqenp5ISEhAY2OjwZtInJ2dsWzZMgBAbm6udP2m/TDko48+wtSpU9GnTx+oVCpMnDgRBw4caPVrRfSwdu/eDYVCgatXrwIA/Pz8dN7LTXNS05+Fb7/9Fq+88gqcnZ3Rq1cvzJ07V4r77LPP8Prrr8PLywuDBg1Cr1698Oijj2L27Nn4+OOPjfalaY67du0ali9fjsGDB0OpVMLZ2RmvvfYaKisrDZ77ww8/4PXXX8fIkSNhbW0NKysrODo6YvLkyYiIiMD333/fotdDCIGMjAz84Q9/wBNPPIH+/ftLef/5559Hfn6+3jnaHKw1bNgwndew6U16D7op7cSJE3jhhRek5/3II4/A398fBw8eNBh/5coV6ToAcOzYMcyePRv9+vWDlZUVPD09sX37dgghWvT8TcFc3Y0Jov9z+/ZtMWrUKAFAKBQK4erqKiZMmCCcnJyEpaWlACCSk5N1zqmvrxfz588XAAQAMWTIEDF+/Hhhb28vAIiePXuKlJQUvWtFRkYKAGLJkiVG++Pk5CQAiOzsbIPnvvDCC8LLy0sAEK6urmLcuHFiyJAhUtzHH38sbG1tBQDRo0cP4eHhIZ544gnh4OAgAIgxY8boXXP79u2iZ8+eAoBQqVTC09NTDB06VHp+v/nNb0R9fb1Jr6uvr68AIFJTU/WOHTt2TPTr108AEJaWlsLd3V089thjwsLCQgAQbm5u4vr163rnafuzc+dO0bt3b2FjYyPGjRsn1Gq1dOy5554z2J/09HTp+2ljYyPGjx8vhg0bJp1jqL/z588Xbm5uAoCws7MTPj4+Oh/fffedEEKI7OxsAUA4OTmJqKgoAUA8+uijYty4cdJ7AoB46623THoNidrK4cOHhY+Pj1AqlQKAGDVqlM57OSYmRorV/iysX79e9OvXT1hYWAhPT0/h6emp8/Ol/Rnu27evGDlypPjVr34l+vfvL73fw8PDDfZFm+O2bt0q+vTpI5RKpfjVr34lnJ2dpXOffPJJvZzz7bffisGDBwsAwsLCQjz22GNi/PjxYvDgwVL++uSTT3TOWbJkiQAgIiMjddpv374t5fz+/fsLT09PMWbMGClP9ujRQ7z99ts65+zatUv4+PhIfRw/frzOa7hr1y6919BQ/nvzzTeFQqEQAISDg4MYP368Tg5btmyZaGxs1Dnnm2++kY6npqaKHj16iL59+4rx48eLRx55RDr22muvGXzNm8NcLd9czWKYJImJiQKAGD16tPjmm290jtXW1or33ntPfP755zrtGzZsEACEtbW1OHjwoNR+584dERQUJCXrL774Que8tiiGe/bsKZydncVXX30lHaupqRFCCHH27FlhZWUlAIgXX3xRSgBaRUVFIiEhQaft0KFDQqFQCCsrK5GUlCQaGhqkY4WFhVKCuf+XyYMYS7DXr18Xffv2FQDE2rVrxa1bt6Rj3333nXjmmWcEAOHr66v3mNpEZWlpKUJCQkRtba10bO/evdIvmKNHj+qc991330mJbunSpaKqqko6lpWVJezs7KTke39/U1NTjfZHS5tgLS0thZWVlfjb3/4mHauvrxcrV66UEntlZaXxF42onRnLL01pf3Z79uwp/P39xc2bN6Vj2lwjhBDJycni0qVLeud/8sknYsCAAQKAOHnypNE+WFpaikWLFony8nLpWFZWlpTD3nnnHZ3zXn31VQFATJ8+Xfzwww86xyoqKkRqaqr4+uuvddqNFcN1dXVi586d4saNGzrtDQ0N4u9//7uwtrYWvXr1arbQu//3RVPG8t/Ro0elPBURESF++eUX6VhaWpro1auXAKCXp5sWw0qlUiQkJOjk6o0bN0rFfWlpqdF+mdJX5urun6tZDJPklVdeEQBEYmJii+KrqqqEnZ2dACD++te/GoyZPHmyACDmzp2r094WxTAAceLECYPn/va3v5V+Wdw/smBIY2Oj8PDwEADEjh07DMYUFhYKhUIh7O3txZ07dx74mFrGEuyqVaukYt2QyspKafTn+PHjOse0z3/69OkGz509e7YAIIKCgnTata/dqFGjdH6BaCUnJ+uMujRlSoIFIP7yl7/oHa+pqZFGzD788EOjj0PU3kwphgcMGNDqgkD7M7Vq1SqjfXjsscd0ikGt1atXCwBi3rx5Ou3+/v4CgEhPT29xP4wVww8SFhYmAIi4uDi9Yw9TDE+bNk0AELNnzzZ4Xnh4uPTa19XVSe1Ni+Hly5frndfY2Cj9h3Pr1q0te5IP6CtzdffP1ZwzTBJHR0cAQHp6utF5ak199tlnqKyshLW1NVatWmUw5k9/+hMAICsrCw0NDW3XWQAeHh6YOHGiXvudO3dw6NAhAMD69et15rYZU1JSgpKSEvTu3RtLliwxGDNu3Dg4OTmhoqICX3755cN1HsD7778PAHjllVcMHre1tcWMGTMAAEePHjUYs3r1aoPtPj4+AKA3xzsjIwPAvQX4e/bsqXfewoUL0bt37xb0/sH+3//7f3ptVlZWeOKJJwz2jaizmj9/PmxtbZuNKSkpQVRUFJ577jn4+flh0qRJmDRpErZu3QoA+Oqrr4ye+/LLL8PS0lKv3djPsTZXv/fee6irqzPpuRhTUFCA0NBQzJ07F1OnTpX6/9577z2w/6aqrq5Gbm4ugH//jrhfUFAQevbsiR9++AGFhYUGYwzlP4VCAW9vbwBtl2OYq7t/rubSaiR56aWX8OabbyInJwdqtRq//vWv4ePjg6eeegpPPvkkLCx03y4XLlwAAAwfPhwqlcrgY44ePRoAUFNTg2vXrmH48OFt1l8PDw+D7RqNRvoF8dRTT7XosYqLiwHcS6S//vWvjcb9/PPPAIBvv/3WlK7qKSsrw48//ggA+M///E+DvwgBSDf5GLueu7u7wfZHH30UAFBVVaXTrv2ejRkzxuB5VlZWcHd3x+nTpx/wDJr3yCOPoG/fvib1jaizMpZrtNatW4f4+Phmb9rS5g5DTP05Xrt2Lfbu3Yt9+/YhIyMD/v7+ePLJJ+Hj44Nx48a1aABAq6GhAS+99BLefffdZuOa67+pSktLpZuRtb8j7te3b18MHjwY165dw/nz56UCtylTX7fWYK6WR65mMUySgQMH4uTJk4iKikJ6ejo+/PBDfPjhhwCA/v37IygoCCEhIdJfqbdv35bOM2bQoEHS59r4tmKsANeOaiuVSlhZWbXosW7dugUAqK2tNXj39P1qampa2MvmrwfcG5Fp7fWMvQY9etz7p09jY6NOuzapNTfK9aARsJYw1q/m+kbUWTX3fj5w4ADi4uLQo0cPRERE4Le//S2GDRsGlUqFHj164OjRo5g+fTrq6+tNfnxjPyujRo3C8ePHER0djSNHjuDAgQPSnf+Ojo4ICwvDyy+/3KLn9sYbb+Ddd9+FlZUVNm3aBH9/fzg6OsLa2hoKhQLvvPMOli9f3mz/TaX9XWBhYYF+/foZjRs0aBCuXbtm9HeHqa9bazBXyyNXsxgmHS4uLti7dy/u3r2LoqIifPbZZ/j444/xz3/+E+vXr8ft27exadMmAP/+Qbx586bRx/vuu++kz5v+4GpHLpobSamurm7Vc7CzswMA1NXVoba2tkUFsY2NDQBg7NixRpeDa0va6wH3km1HbWVqY2ODioqKZv8waes/Woi6M+2yVq+99prOkmJabTmi2tQTTzyBDz74AL/88gsKCwuRl5eH9PR0nDx5Uvp3fksKYm3/33jjDYP/Lm+P/mt/FzQ0NODnn382WhBrf3+0RdHXWszV8sA5w2RQz549MW7cOLz66qv49NNPpXlvSUlJUsxjjz0GALh8+bLRv4bPnj0LALC2tpbmuQH//mvU2FqYt27dwk8//dSqvru7u0tzqY4fP96ic7T/qjt37lyzW4u2lSFDhkhJ9fPPP2/362mNGDECwL+nhdzvzp07uHjxosFjpvzrlaiza6v38zfffAMAmDx5ssHj7f3z3atXL3h7e2PdunU4ceIEgoKCAAD//d//3aLzzdF/V1dXadqd9nfE/W7duoUbN24AAB5//PE270NLMVfLA4thapEpU6YAAMrLy6XCd9KkSbCzs0NNTQ127txp8LwtW7YAAPz9/XXmHLu5uQEATp06ZfAGkJYmckOUSiVmz54NANi8eXOLFl9/4okn4Obmhvr6esTFxbX62i3Vs2dPPPfccwCA2NjYdtnMw5Cnn34awL3RIEPX/Nvf/oY7d+4YPNfa2hrAvakkRF1dW72ftY9TVlamd+yHH37Anj17HurxTaXN1Yb6Y0hz/S8pKZFuRm7uXFNfQ5VKBV9fXwDAm2++aTAmMTERd+/exYABAzB+/HiTHr8tMVfLA4thkoSGhiIpKUlvtLa8vByxsbEA7t1Iov1BU6lUCA4OBgBERETgo48+ks6pq6tDSEgIcnNzYWFhgfXr1+s85rRp06BSqaRdlJr+sP/973/Hpk2bjN6o0BLR0dGwsrLCJ598gkWLFuGHH37QOX769GkkJiZKXysUCrz55ptQKBSIi4vD+vXr9XYUqq6uxsGDBxEYGNjqfjUVERGBfv364dixY5g3bx4uX76sc/zu3bv47LPPsHz5cmmE5GGtXLkS9vb2OHv2LFasWKEzFeXTTz9FcHCw0dfd1dUVwL3R85bubkXUWWnfz8bu/m8pbVG3adMmnD9/Xmq/fPkyZs+e3S4Fycsvv4x3331X779YN2/eREJCAgBgwoQJLXosbf9DQ0N18kxRURF+85vfGFzJQOthXsPw8HAoFAp89NFH+Mtf/qKz2pB2HjZwb0Wgh/ld0BaYq2XAzEu7USfy7LPPSusOOjo6Ci8vLzFy5EhppyYbGxuRl5enc059fb147rnndM6bMGGCzg509+9ap7Vt2zbpvD59+ojx48eLgQMHCgAiOjr6gesMN7dGsRBC/O///q+wsbGR+jFy5EjxxBNPSIunG9qBbteuXdLztbS0FKNGjRITJ04Ubm5u0s5OTk5OJryqze9qdPLkSZ2diFxcXMSTTz4pRo0aJS24DwPreBpr12puncn09HRp1yQbGxsxYcIEMXz4cAFA/Pa3vxVTpkwRAMTevXt1zmtsbBSjR48WwL3d+SZMmCB8fX2Fr6+vwV2NjGnteqdEben999+Xfo6GDx8uJk+eLHx9fUVsbKwU09zPrtaNGzfEo48+KvB/Gwx5eHiI0aNHix49eog+ffqIt956y+jPxIPWOjb28zRmzBhpYwkXFxcxceJEnd3QHn300RZvunH69GmhUqmkTSw8PT3FiBEjBAAxdOhQsWnTJqO55I033pBew8cff1xMmTJF+Pr66rxepuxAN2HCBGm9XvzfZhPN7UBnTEt/R9yPuVqXnHI1R4ZJ8uc//xnh4eGYNGkSGhsbUVRUhMuXL8PZ2Rl/+MMfcObMGb15ZRYWFvjHP/6Bv/3tb5g2bRpu376NoqIiqFQqLFiwAAUFBUZHUtesWYP9+/fDy8sLdXV1uHDhAlxdXXHw4EH8+c9/fujn8x//8R8oKSnBq6++Cjc3N1y+fBkajQb9+vXD4sWLpSkcTb300ks4d+4c/vjHP8LNzQ3ffPMNTp8+jbt378LX1xdxcXH45JNPHrpvWl5eXigpKUFsbCyeeuop/Pzzz/jyyy9RXl6OMWPG4PXXX0d+fj6cnJza7JrPPvssjh8/jt/85jewtLTEmTNnYGVlhb/+9a947733pBEI7Y2IWgqFAocPH8aSJUvQt29fFBUVITc3F7m5uUb/XUfUWT333HN45513MHHiRPz44484duwYcnNzdUZ3W0KtVuPkyZNYuHAhHBwcoNFoUF5ejiVLluDUqVMYNWpUm/c9MTERr732GiZMmICamhp89dVXuH79Ojw8PLBu3TqcOXNGuqfjQUaPHo3jx4/j2WefhZWVFS5cuID6+nqsXbsWp06d0lkR6H5BQUF44403MGbMGFy9ehV5eXnIzc3FlStXWnTtoKAgfP7553j++efRu3dvFBUVoba2FjNmzMD777+P1NTUTjP/lbm6e1MI0YIJlUQkC3fv3kXfvn1RWVmJ4uJieHp6mrtLRER0H+bqtsWRYSKSvPfee6isrES/fv0euNEAERGZB3N122IxTCQzhw4d0tvGVQiBDz74QFpndNWqVXo7DhIRUcdhru44fAWJZEaj0SAoKAgWFhZwdnaGg4MDvvnmG2ldZz8/P4SHh5u5l0RE8sZc3XE4Z5hIZkpKSvDf//3fyM3NxXfffYeKigrY2tpi9OjRWLBgAZYvX272pYyIiOSOubrjsBgmIiIiItninGEiIiIiki3OGb5PY2MjysrKYGtr22nWNySi7kUIgdu3b0OtVqNHj+43JsE8SkTtrS3zKIvh+5SVlWHo0KHm7gYRycD169cxZMgQc3ejzTGPElFHaYs8ymL4Pra2tgDuvbj37+pCRNQWKisrMXToUCnfdDfMo0TU3toyj7IYvo/2X3p2dnZM4kTUrrrrFALmUSLqKG2RR7vfZDUiIiIiohZiMUxEREREssVimIiIiIhki8UwEREREckWi2EiIiIiki0Ww0REREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2WIxTERERESyxWKYiIiIiGSLxTARERERyZaFuTtApnFed8ik+CubZ7dTT4iIuiZT8yjAXErUnXFkmIiIiIhki8UwEREREckWi2EiIiIiki0Ww0REREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2WIxTERERESyxWKYiIiIiGSLxTARERERyRaLYSIiIiKSLRbDRERERCRbLIaJiIiISLZYDBMRERGRbLEYJiIiIiLZYjFMRERERLLFYpiIiIiIZIvFMBERERHJFothIiIiIpItFsNEREREJFsshomIiIhItlgMExEREZFssRgmInpIaWlpeOWVVzB+/HgolUooFArs3r3baHxlZSUAYNSoUVAqlXByckJwcLDUbsi+ffvg5eUFlUoFBwcHzJo1C4WFhUbjNRoNAgIC0L9/f1hZWcHT0xPbt29HY2Ojwfi6ujpER0fD3d0dvXv3xqBBgxAYGIibN2+27EUgIuqiWAwTET2k8PBwvP3227h69SoGDRrUbGx1dTVmzZoFAHB1dUVQUBA8PDyQkJAAX19fVFdX652zadMmLFy4EN9//z1WrlyJgIAA5Ofnw8fHBzk5OXrxJSUlmDBhAtLT0+Hv74+1a9cCANasWYOVK1fqxTc2NuLZZ59FZGQk+vbti1dffRWTJk1CamoqJk6cyIKYiLo1FsNERA8pJSUFV65cwY8//miw2GwqPj4eZ86cAQCkp6dj8+bNyMjIQEREBIqKihAfH68Tr9FoEBkZCXd3d5w+fRpbtmzBzp078fnnn8PCwgKBgYFoaGjQOWfVqlWoqKhAeno60tLSEBcXhy+//BLTp09HcnIysrOzdeL37NmDzMxMvPjiizh+/Dg2b96Mf/zjH0hJScG1a9fwn//5n23wKhERdU4shomIHtKvf/1rODk5PTBOCIGUlBTY2NjoHQsNDYWDgwN27doFIYTUnpqaioaGBoSFhcHe3l5qHzlyJBYvXoxLly7h6NGjUvvFixeRl5cHPz8/aQQaACwtLRETEwMASE5O1rm29uvNmzdDoVBI7cuWLcPjjz+Ov//977h9+/YDnx8RUVfEYpiIqINoNBqUlZVh4sSJesd69+6NKVOm4MaNGygtLZXatdMgZs6cqXeOv78/ACA3N7dF8V5eXujTp49O/J07d3Dy5EmMGDHCYEE/c+ZM1NXV4cSJEy17kkREXQyLYSKiDqLRaAAALi4uBo+7ubnpxGk/t7GxwcCBA1sc3/RYUwqFAq6urigrK0NNTQ0A4NKlS2hsbDQYb+waRETdiYW5O0BEJBcVFRUAADs7O4PHte3aOO3nAwYMMCkegM6UCmPnWFtbmxRvTF1dHerq6qSvm1sVg4ios+HIMBERPZTY2FjY29tLH0OHDjV3l4iIWozFMBFRB9GOvhobOdW2Nx2ltbe3NzoqayweMD6Sqz1HO+Lb0nhjI8fAvZv/KioqpI/r168bjSUi6mxMLoaFEDh48CD8/PwwaNAgWFtbY8SIEXjllVdw+fJlvfjKykoEBwfDycmp0ywuT0RkDtr5t5cuXTJ43NB8Xzc3N1RVVRlc69dYfNNjTQkhUFpaCrVaDZVKBeDe/OUePXoYnRPc3BxkLaVSCTs7O50PIqKuwuRi+E9/+hOee+45XLhwAXPnzsWaNWswbNgwJCcnY+zYsTh79qwUW11dDV9fXyQkJGDEiBGdYnF5IiJzcXNzg1qtxsmTJ/WO3blzB3l5eVCr1XB1dZXafX19AQBZWVl652RmZurEAMDUqVONxhcUFKC8vFwnvnfv3vDy8sKFCxdw9epVvXOysrKgVCoNroBBRNQdmFQM37x5E4mJiXB2dsb58+eRlJSEuLg4HDlyBG+++SZu376NN998U4qPj49HUVERQkJCkJWV1SkWlyciMheFQoHAwEBUVVXpHYuNjcWtW7cQGBiot9avhYUFYmJidKYynDt3Dnv37oWLiwumTZsmtbu7u2PKlCnIzs7G4cOHpfb6+nqEh4cDAFasWKFz7ZdffhkAsG7dOr01jr/++mu88MILHO0lom5LIZpmvgc4ceIEnnrqKSxcuBBpaWk6xzQaDdzd3TF79mx8/PHHEEJgyJAhqKysxM2bN6V/yQH3RkDUajWsra1x/fp1KfGvX78esbGx2LNnDxYvXqzz+KtWrcKOHTuQmZkprZ958eJFjBgxAn5+fjqLzgPAyZMn8eSTT2LBggXYt29fi1+QyspKaY5eZ0z+zusOmRR/ZfPsduoJEWmlpKTg2LFjAIAzZ87gq6++go+PjzTCO3fuXMydOxfAvf+YPfXUUzhz5gz8/PwwceJEFBcXIyMjA2PHjsWxY8d08iUAxMTEIDw8HI6Ojpg/fz6qq6uxf/9+1NbWIjMzE35+fjrxJSUl8Pb2Rm1tLQICAqBWq3HkyBGcPn0agYGBeptu3L17F7Nnz0ZmZiYmTpyIqVOn4vLly/if//kfDB48GAUFBQaXdjOmu+VRgLmUqLNpyzxj0tJqbm5u6NWrF/Lz83H79m3Y2tpKx7QjENoRCu3i8v7+/nqJXbu4/IcffojS0lJpLtqDFpffsWMHcnNzpeOmLi7f2bQmIRNR53Ps2DHs2bNHpy0/Px/5+fkAAGdnZ6kYVqlUOHToEBwdHaHRaHDs2DEMHDgQQUFBiIyM1MuXABAWFgZnZ2ckJiYiKSkJvXr1gre3N6KjozFhwgS9eA8PDxQUFCAsLAwZGRmoqqqCq6srtm3bhtWrV+vF9+zZEx9++CHi4uLw7rvvIiEhAQ4ODli6dCk2btxoUiFMRNTVmFQM9+vXDzExMXj99dfx+OOPY86cObC1tcWZM2fw6aef4uWXX8aaNWsAPPimi6Y3eTT9vK0Xly8sLERNTQ2sra0N9oPrYxLRw9q9ezd2797d4njtygznzp1r8YjGwoULsXDhwhZfw93dHf/4xz9aHK9UKhEREYGIiIgWn0NE1B2YvOnGn/70J6jVarzyyitISkqS2r29vfH73/8elpaWAExb+F2rvReXNyQ2NhZRUVEGjxERERFR92byahIbN27E0qVLERoaiuvXr6OqqgrHjh1DQ0MD/Pz8cPDgwfboZ7vh+phERERE8mVSMXz06FH8+c9/xh/+8AesX78eQ4YMgUqlgo+PDz7++GNYWVkhKCgIQOsWcm/vxeUN4fqYRERERPJlUjF86NC9G77uv3MZAPr374/Ro0fj2rVr+Omnn5pd+L1pe0cuLk9ERERE1JRJxfAvv/wCAPjxxx8NHte2K5VKaXH5/Px8vc01zLW4PBERERFRUyYVwz4+PgCAN998U29qwp49e1BaWopx48bB1tZWZ3H56OhonVhzLi5PRERERKRl0moSzz//PHbu3ImcnBy4ublhzpw5cHBwQHFxMT755BMolUokJiZK8SEhIfjoo48QHx+PU6dOYdy4cTqLy4eEhOg8vru7OzZs2IDw8HB4enrqLC5fX1+P5ORkWFjodjkpKQne3t6YN2+ewcXlDU3pICIiIiICTBwZ7tmzJ44cOYK4uDgMHToU+/fvR2JiIkpKSvC73/0OhYWFmDRpkhSvUqmQk5ODoKAgnD9/Hlu2bMHZs2cRFBSEnJwco4vLp6WlYcCAAUhKSsKBAwfg7e2N/Px8g4WtdnH5OXPmICMjA1u3bsXdu3exbds27Ny5sxUvCRERERHJhUnbMctBR24j2hE70HELUaLOp7NvV/ywOvvz43bMRF1fW+YZk9cZJiIiIiLqLlgMExEREZFssRgmIiIiItliMUxEREREssVimIiIiIhki8UwEREREckWi2EiIiIiki0Ww0REREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2bIwdweofTmvO2TyOVc2z26HnhARERF1PhwZJiIiIiLZYjFMRERERLLFYpiIiIiIZIvFMBERERHJFm+gIyIiegBTb0bmjchEXQeLYSIi6rJas2IOEVFTnCZBRERERLLFYpiIiIiIZIvFMBERERHJFothIiIiIpItFsNEREREJFsshomIiIhItlgMExEREZFssRgmIiIiItliMUxEREREssVimIiIiIhki8UwEREREckWi2EiIjP56KOP4Ofnh0GDBsHa2hojRozAK6+8gsuXL+vFVlZWIjg4GE5OTlAqlXByckJwcDAqKyuNPv6+ffvg5eUFlUoFBwcHzJo1C4WFhUbjNRoNAgIC0L9/f1hZWcHT0xPbt29HY2NjmzxfIqLOiMUwEZGZLFq0CBcuXMDcuXOxZs0aDBs2DMnJyRg7dizOnj0rxVVXV8PX1xcJCQkYMWIEgoKC4OHhgYSEBPj6+qK6ulrvsTdt2oSFCxfi+++/x8qVKxEQEID8/Hz4+PggJydHL76kpAQTJkxAeno6/P39sXbtWgDAmjVrsHLlynZ7DYiIzM3C3B0gIpKb77//HgDg6OiIM2fOwM7OTjqWmJiIoKAgvPnmm3jnnXcAAPHx8SgqKkJISAji4uKk2MjISERHRyM+Ph5RUVFSu0ajQWRkJNzd3VFQUAB7e3sAwNq1a+Hl5YXAwECcP38eFhb//hWwatUqVFRU4NChQ5g1axYAYOPGjXjmmWeQnJyMBQsWwM/Pr/1eFCIiM+HIMBFRB7t27RoA4Mknn9QphAFg9uzZAIAffvgBACCEQEpKCmxsbBAREaETGxoaCgcHB+zatQtCCKk9NTUVDQ0NCAsLkwphABg5ciQWL16MS5cu4ejRo1L7xYsXkZeXBz8/P6kQBgBLS0vExMQAAJKTk9viqRMRdToshomIOpiLiwsA4MSJE7h9+7bOscOHDwMApk2bBuDeKG9ZWRl8fHygUql0Ynv37o0pU6bgxo0bKC0tldq10yBmzpypd21/f38AQG5ubovivby80KdPH514IqLuhNMkiIg6WN++fQHcGyF+/PHHMWfOHNja2uLMmTP49NNP8fLLL2PNmjUA7hXDAODm5mbwsbTtGo1G53MbGxsMHDiw2Xit5q6hUCjg6uqKwsJC1NTUwNraWi+mrq4OdXV10tfN3dRHRNTZsBgmIjKTlJQUvPrqq0hKSpLavL298fvf/x6WlpYAgIqKCgDQme7QlHaahTZO+/mAAQNMim/pNQwVw7GxsTpzlomIuhJOkyAiMpNVq1YhNDQU169fR1VVFY4dO4aGhgb4+fnh4MGD5u5ei4WGhqKiokL6uH79urm7RETUYiyGiYg6mHb+7csvv4z169djyJAhUKlU8PHxwccffwwrKysEBQUB+PdobdOR3Ka0UxKajura29ubHN+Sa9x/s5+WUqmEnZ2dzgcRUVfBYpiIqINlZWUBACZPnqx3rH///hg9ejSuXbuGn376yeAc36YMzfd1c3NDVVUVbt682eJ4Y9cQQqC0tBRqtVrvBj4iou6AxTARUQf75ZdfAAA//fSTweM//vgjgHsjrm5ublCr1cjPz9fbXOPOnTvIy8uDWq2Gq6ur1O7r6wvg30V3U5mZmToxADB16lSj8QUFBSgvL9eJJyLqTlgMExF1sIkTJwIA/uu//ktvasKePXtQWlqKcePGwdbWFgqFAoGBgaiqqkJ0dLRObGxsLG7duoXAwEAoFAqpfdmyZbCwsEBMTIzO4587dw579+6Fi4uLtHQbALi7u2PKlCnIzs6WlnYDgPr6eoSHhwMAVqxY0XYvABFRJ6IQTVdqJ1RWVkrz7dp73pvzukPt+vitdWXzbHN3gahbu3XrlrS8Wv/+/TFnzhw4ODiguLgYn3zyCZRKJT799FNMmjQJwL3tmCdNmoSioiLMmDED48aNQ3FxMTIyMjB27FgcO3ZMbwpDTEwMwsPD4ejoiPnz56O6uhr79+9HbW0tMjMz9XaTKykpgbe3N2praxEQEAC1Wo0jR47g9OnTCAwMNGnTDeZR5lGi9taWeYYjw0REHaxnz54AgKioKAwdOhT79+9HYmIiSkpK8Lvf/Q6FhYVSIQwAKpUKOTk5CAoKwvnz57FlyxacPXsWQUFByMnJMTiXNywsDGlpaRgwYACSkpJw4MABeHt7Iz8/3+C2yh4eHigoKMCcOXOQkZGBrVu34u7du9i2bRt27tzZfi8GEZGZcWT4PhzR4IgGUXvryDxjDsyjzKNE7Y0jw0REREREbYDFMBERERHJFothIiIiIpItFsNEREREJFsshomIiIhItlpdDH/wwQeYMWMG+vXrBysrKwwbNgwLFizA9evXdeIqKysRHBwMJycnKJVKODk5ITg4WNrr3pB9+/bBy8sLKpUKDg4OmDVrFgoLC43GazQaBAQEoH///rCysoKnpye2b9+OxsbG1j49IiIiIpIBC1NPEEJg5cqVePvtt+Hi4oIXX3wRtra2KCsrQ25uLq5evYqhQ4cCuLdQvK+vr7RQ/IIFC1BcXIyEhARkZ2cbXCh+06ZNCAsLg6OjI1auXImqqiocOHAAPj4+yMzMlLYN1dIuFF9TU4OAgAAMHjwYGRkZWLNmDU6fPo2333679a8OEREREXVrJhfDb731Ft5++22sXr0aW7dulRaP12poaJA+j4+PR1FREUJCQhAXFye1R0ZGIjo6GvHx8YiKipLaNRoNIiMj4e7ujoKCAtjb2wMA1q5dCy8vLwQGBuL8+fOwsPh3t1etWoWKigocOnQIs2bNAgBs3LgRzzzzDJKTk7FgwQKDC8wTEREREZk0TaK2thZRUVEYPnw4EhMT9QphAFKhKoRASkoKbGxsEBERoRMTGhoKBwcH7Nq1C033/EhNTUVDQwPCwsKkQhgARo4cicWLF+PSpUs4evSo1H7x4kXk5eXBz89PKoQBwNLSEjExMQBg0haiRERERCQvJhXDn3zyCf71r39h7ty5uHv3Lg4ePIjNmzdjx44dKC0t1YnVaDQoKyuDj4+P3lSI3r17Y8qUKbhx44bOeTk5OQCAmTNn6l3b398fAJCbm9uieC8vL/Tp00cnnoiIiIioKZOmSWhvYrOwsMCYMWNw4cIF6ViPHj0QFBSEN954A8C9YhgA3NzcDD6Wtl2j0eh8bmNjg4EDBzYbr9XcNRQKBVxdXVFYWIiamhpYW1sb7EddXR3q6uqkr5u7sY+IiIiIuheTRoZ/+OEHAMCWLVtgZ2eHgoIC3L59G3l5eXB3d8eWLVuQlJQEAKioqAAAnekOTWn3kdbGaT83Nd7Ua9wvNjYW9vb20of25j8iIiIi6v5MKoa1S5X16tUL6enpmDBhAmxsbDB58mS8//776NGjB7Zs2dIuHW0voaGhqKiokD7uXxqOiIiIiLovk6ZJaEdgx48fD7VarXNs5MiRGD58OEpLS1FeXi7FGhuV1U5HaDqqa29vb3J8S66hHSE2RKlUQqlUGj1ORERERN2XSSPDI0aMAAD06dPH4HFte21trcE5vk0Zmu/r5uaGqqoq3Lx5s8Xxxq4hhEBpaSnUarXeDXxERERERICJxbB2vd6vv/5a71h9fT1KS0uhUqnQv39/uLm5Qa1WIz8/H9XV1Tqxd+7cQV5eHtRqNVxdXaV2X19fAEBWVpbe42dmZurEAJA24DAUX1BQgPLycp14IiIiIqKmTCqGXVxcMHPmTJSWliIlJUXn2ObNm1FeXo558+bBwsICCoUCgYGBqKqqQnR0tE5sbGwsbt26hcDAQCgUCql92bJlsLCwQExMjM7Uh3PnzmHv3r1wcXHBtGnTpHZ3d3dMmTIF2dnZOHz4sNReX1+P8PBwAMCKFStMeYpEREREJCMK0XTXixa4dOkSvL298cMPP2D27Nl47LHHcOrUKRw9ehROTk44ceKEtDRadXU1Jk2aJG3HPG7cOBQXFyMjIwNjx441uB1zTEwMwsPD4ejoiPnz56O6uhr79+9HbW0tMjMz9XaT027HXFtbi4CAAKjVahw5cgSnT59GYGCgyZtuVFZWSnOXm5tr3Bac1x1q18dvrSubZ5u7C0TdWkfmGXNgHmUeJWpvbZlnTBoZBu6NDhcWFmLp0qX48ssvsW3bNmg0GqxevRoFBQU6awSrVCrk5OQgKCgI58+fx5YtW3D27FkEBQUhJyfH4FzesLAwpKWlYcCAAUhKSsKBAwfg7e2N/Px8g9sqe3h4oKCgAHPmzEFGRga2bt2Ku3fvYtu2bdi5c6epT4+IiIiIZMTkkeHujiMaHNEgam8cGW47zKNE8tSWecakpdVIHlrzy4WJn4iIiLoik6dJEBERERF1FyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2WIxTERERESyxWKYiIiIiGSLxTARERERyRaLYSIiIiKSLRbDRERERCRbLIaJiIiISLZYDBMRERGRbLEYJiIiIiLZYjFMRERERLLFYpiIiIiIZIvFMBERERHJFothIiIiIpItFsNEREREJFsshomIzOiDDz7AjBkz0K9fP1hZWWHYsGFYsGABrl+/rhNXWVmJ4OBgODk5QalUwsnJCcHBwaisrDT62Pv27YOXlxdUKhUcHBwwa9YsFBYWGo3XaDQICAhA//79YWVlBU9PT2zfvh2NjY1t9nyJiDobC3N3gIhIrv74xz9i9+7dcHFxwYsvvghbW1uUlZUhNzcXV69exdChQwEA1dXV8PX1RVFREWbMmIEFCxaguLgYCQkJyM7OxrFjx6BSqXQee9OmTQgLC4OjoyNWrlyJqqoqHDhwAD4+PsjMzMTUqVN14ktKSuDt7Y2amhoEBARg8ODByMjIwJo1a3D69Gm8/fbbHfWyEBF1KBbDRERmsnv3bqxevRpbt25Fz549dY41NDRIn8fHx6OoqAghISGIi4uT2iMjIxEdHY34+HhERUVJ7RqNBpGRkXB3d0dBQQHs7e0BAGvXroWXlxcCAwNx/vx5WFj8+1fAqlWrUFFRgUOHDmHWrFkAgI0bN+KZZ55BcnIyFixYAD8/v3Z5HYiIzInTJIiIOlhtbS0AwNnZGYmJiXqFMACpUBVCICUlBTY2NoiIiNCJCQ0NhYODA3bt2gUhhNSempqKhoYGhIWFSYUwAIwcORKLFy/GpUuXcPToUan94sWLyMvLg5+fn1QIA4ClpSViYmIAAMnJyW3wzImIOh8Ww0REHSw7OxsA8B//8R+4e/cuDh48iM2bN2PHjh0oLS3VidVoNCgrK4OPj4/eVIjevXtjypQpuHHjhs55OTk5AICZM2fqXdvf3x8AkJub26J4Ly8v9OnTRyeeiKg74TQJIqIOdurUKQBAz549MWbMGFy4cEE61qNHDwQFBeGNN94AcK8YBgA3NzeDj6Vt12g0Op/b2Nhg4MCBzcZrNXcNhUIBV1dXFBYWoqamBtbW1noxdXV1qKurk75u7qY+IqLOhiPDREQd7McffwQAbN++HXZ2digoKMDt27eRl5cHd3d3bNmyBUlJSQCAiooKANCZ7tCUnZ2dTpz2c1PjTb1GU7GxsbC3t5c+tDf+ERF1BSyGiYg6mHapsl69eiE9PR0TJkyAjY0NJk+ejPfffx89evTAli1bzNzLlgsNDUVFRYX0cf+ycEREnRmnSRARdTDtSOsTTzwBtVqtc2zkyJEYPnw4SktLUV5eLo3WGhuV1U5JaDqqa29vb3J8S66h7ff9lEollEqlwWNERJ0dR4aJiDqYdm6usWkJffr0AXBv1QlDc3ybMjTf183NDVVVVbh582aL441dQwiB0tJSqNVqvRv4iIi6AxbDREQdbPLkyQCgc+OcVn19PUpLS6FSqdC/f3+4ublBrVYjPz8f1dXVOrF37txBXl4e1Go1XF1dpXZfX18AQFZWlt7jZ2Zm6sQAkDbgMBRfUFCA8vJynXgiou6ExTARUQcbPnw4AODy5ctISUnRObZ582aUl5dj3rx5sLCwgEKhQGBgIKqqqhAdHa0TGxsbi1u3biEwMBAKhUJqX7ZsGSwsLBATE6Mz9eHcuXPYu3cvXFxcMG3aNKnd3d0dU6ZMQXZ2Ng4fPiy119fXIzw8HACwYsWKtnsBiIg6Ec4ZJiIyk/79+2PFihVIT0/HY489hlOnTuHo0aNwcnLCX//6VykuJCQEH330EeLj43Hq1CmMGzcOxcXFyMjIwNixYxESEqLzuO7u7tiwYQPCw8Ph6emJ+fPno7q6Gvv370d9fT2Sk5N1dp8DgKSkJHh7e2PevHkICAiAWq3GkSNHcPr0aQQGBnL3OSLqtjgyTERkJjk5OVi6dCm+/PJLbNu2DRqNBqtXr0ZBQYHOGsEqlQo5OTkICgrC+fPnsWXLFpw9exZBQUHIyckxOJc3LCwMaWlpGDBgAJKSknDgwAF4e3sjPz/fYGHr4eGBgoICzJkzBxkZGdi6dSvu3r2Lbdu2YefOne36OhARmZNCNN3Dk1BZWSndiW3szum24rzuULs+fke6snm2ubtA1GV0ZJ4xB+ZR5kSi9taWeYYjw0REREQkWyyGiYiIiEi2eAMdERFRG2vN9A1OrSAyD44MExEREZFssRgmIiIiItliMUxEREREssVimIiIiIhki8UwEREREckWi2EiIiIiki0Ww0REREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2WIxTERERESyxWKYiIiIiGTroYvh+Ph4KBQKKBQKnDhxwmBMZWUlgoOD4eTkBKVSCScnJwQHB6OystLo4+7btw9eXl5QqVRwcHDArFmzUFhYaDReo9EgICAA/fv3h5WVFTw9PbF9+3Y0NjY+7FMkIiIiom7qoYrhr7/+GhEREVCpVEZjqqur4evri4SEBIwYMQJBQUHw8PBAQkICfH19UV1drXfOpk2bsHDhQnz//fdYuXIlAgICkJ+fDx8fH+Tk5OjFl5SUYMKECUhPT4e/vz/Wrl0LAFizZg1Wrlz5ME+RiIiIiLqxVhfDd+/exZIlSzBmzBjMmzfPaFx8fDyKiooQEhKCrKwsbN68GRkZGYiIiEBRURHi4+N14jUaDSIjI+Hu7o7Tp09jy5Yt2LlzJz7//HNYWFggMDAQDQ0NOuesWrUKFRUVSE9PR1paGuLi4vDll19i+vTpSE5ORnZ2dmufJhERERF1Y60uhuPi4lBcXIx33nkHPXv2NBgjhEBKSgpsbGwQERGhcyw0NBQODg7YtWsXhBBSe2pqKhoaGhAWFgZ7e3upfeTIkVi8eDEuXbqEo0ePSu0XL15EXl4e/Pz8MGvWLKnd0tISMTExAIDk5OTWPk0iIiIi6sZaVQyfPXsWUVFRCA8Px8iRI43GaTQalJWVwcfHR28qRe/evTFlyhTcuHEDpaWlUrt2GsTMmTP1Hs/f3x8AkJub26J4Ly8v9OnTRyeeiIiIiEjL5GK4oaEBS5cuxeOPP45169Y1G6vRaAAAbm5uBo9r27Vx2s9tbGwwcODAFscbu4ZCoYCrqyvKyspQU1PTbF+JiIiISH4sTD1h06ZNKC4uxsmTJ2FpadlsbEVFBQDoTHdoys7OTidO+/mAAQNMim/pNaytrfWO19XVoa6uTvq6uRUuiIiIiKh7MWlkuLi4GBs3bsSf/vQn/OpXv2qvPnWo2NhY2NvbSx9Dhw41d5eIiIiIqIOYVAwvWbIELi4u2LBhQ4vitaO1TUdym9KOwjYd1bW3tzc5viXX0I4Q3y80NBQVFRXSx/Xr140+HyIiIiLqXkyaJlFcXAzg3s1vhjz11FMAgA8++ABz5841OMe3KUPzfd3c3HD8+HHcvHlTb96wsXhj1xBCoLS0FGq12uhayEqlEkql0uAxIiIiIureTCqGly9fbrA9Ly8PGo0Gc+bMQf/+/eHs7AzgXqGqVquRn5+P6upqnYL0zp07yMvLg1qthqurq9Tu6+uL48ePIysrC4sXL9a5TmZmphSjNXXqVABAVlaW3g19BQUFKC8vxzPPPGPK0yQiIiIimTCpGE5JSTHYvnTpUmg0GoSGhuLJJ5+U2hUKBQIDAxEdHY3o6GjExcVJx2JjY3Hr1i2sWbMGCoVCal+2bBneeOMNxMTE4Nlnn5WmQZw7dw579+6Fi4sLpk2bJsW7u7tjypQpyM7OxuHDh6W1huvr6xEeHg4AWLFihSlPk4iIiIhkwuTVJEwVEhKCjz76CPHx8Th16hTGjRuH4uJiZGRkYOzYsQgJCdGJd3d3x4YNGxAeHg5PT0/Mnz8f1dXV2L9/P+rr65GcnAwLC91uJyUlwdvbG/PmzUNAQADUajWOHDmC06dPIzAwEH5+fu39NImIiIioC2r1DnQtpVKpkJOTg6CgIJw/fx5btmzB2bNnERQUhJycHINzecPCwpCWloYBAwYgKSkJBw4cgLe3N/Lz8w0Wth4eHigoKMCcOXOQkZGBrVu34u7du9i2bRt27tzZ3k+RiIiIiLoohWi6FzKhsrJSWtHC2AoUbcV53aF2ffzO7srm2ebuApFZdGSeMQfm0dZhTiRqubbMM+0+MkxERERE1FmxGCYiIiIi2WIxTERERESyxWKYiIiIiGSLxTARERERyRaLYSIiIiKSLRbDRERERCRbLIaJiMwsPj4eCoUCCoUCJ06cMBhTWVmJ4OBgODk5QalUwsnJCcHBwaisrDT6uPv27YOXlxdUKhUcHBwwa9YsFBYWGo3XaDQICAhA//79YWVlBU9PT2zfvh2NjY0P/RyJiDorFsNERGb09ddfIyIiwuBunFrV1dXw9fVFQkICRowYgaCgIHh4eCAhIQG+vr6orq7WO2fTpk1YuHAhvv/+e6xcuRIBAQHIz8+Hj48PcnJy9OJLSkowYcIEpKenw9/fH2vXrgUArFmzBitXrmyz50tE1NmwGCYiMpO7d+9iyZIlGDNmDObNm2c0Lj4+HkVFRQgJCUFWVhY2b96MjIwMREREoKioCPHx8TrxGo0GkZGRcHd3x+nTp7Flyxbs3LkTn3/+OSwsLBAYGIiGhgadc1atWoWKigqkp6cjLS0NcXFx+PLLLzF9+nQkJycjOzu7XV4DIiJzYzFMRGQmCQkJKC4uxjvvvIOePXsajBFCICUlBTY2NoiIiNA5FhoaCgcHB+zatQtCCKk9NTUVDQ0NCAsLg729vdQ+cuRILF68GJcuXcLRo0el9osXLyIvLw9+fn6YNWuW1G5paYmYmBgAQHJycps8ZyKizobFMBGRmcTFxSE8PBwjR440GqPRaFBWVgYfHx+9qRS9e/fGlClTcOPGDZSWlkrt2mkQM2fO1Hs8f39/AEBubm6L4r28vNCnTx+deCKi7oTFMBFRB9NOURgxYgTWrVvXbKxGowEAuLm5GTyubdfGaT+3sbHBwIEDWxxv7BoKhQKurq4oKytDTU1Ns30lIuqKLMzdASIiudmyZQsAYPv27bC0tGw2tqKiAgB0pjs0ZWdnpxOn/XzAgAEmxbf0GtbW1nrH6+rqUFdXJ33d3AoXRESdDUeGiYg6UHFxMf76178CAMaOHWvezrSR2NhY2NvbSx9Dhw41d5eIiFqMxTARUQdasmQJhg0b1uJ47Wht05HcprSjsE1Hde3t7U2Ob8k1tCPE9wsNDUVFRYX0cf36daPPh4ios+E0CSKiDlRcXCx9bmhawlNPPQUA+OCDDzB37lyDc3ybMjTf183NDcePH8fNmzf15g0bizd2DSEESktLoVarja6FrFQqoVQqDR4jIursODJMRNSBli9fjkWLFgEAFi1ahOXLl2P58uVSQTpnzhwsX74czs7OAO4Vqmq1Gvn5+Xqba9y5cwd5eXlQq9VwdXWV2n19fQEAWVlZetfPzMzUiQGAqVOnGo0vKChAeXm5TjwRUXfCYpiIqAOlpKRg+/btAO7dQJeSkoKUlBR4e3sDuDflICUlRZpPrFAoEBgYiKqqKkRHR+s8VmxsLG7duoXAwEAoFAqpfdmyZbCwsEBMTIzO1Idz585h7969cHFxwbRp06R2d3d3TJkyBdnZ2Th8+LDUXl9fj/DwcADAihUr2vaFICLqJDhNgoiokwsJCcFHH32E+Ph4nDp1CuPGjUNxcTEyMjIwduxYhISE6MS7u7tjw4YNCA8Ph6enJ+bPn4/q6mrs378f9fX1SE5OhoWFbvpPSkqCt7c35s2bh4CAAKjVahw5cgSnT59GYGAg/Pz8OvIpExF1GI4MExF1ciqVCjk5OQgKCsL58+exZcsWnD17FkFBQcjJyTE4lzcsLAxpaWkYMGAAkpKScODAAXh7eyM/P99gYevh4YGCggLMmTMHGRkZ2Lp1K+7evYtt27Zh586dHfE0iYjMQiGa7uFJqKyslO7ENnbndFtxXneoXR+/s7uyeba5u0BkFh2ZZ8yBebR1mBOJWq4t8wxHhomIiIhItlgMExEREZFssRgmIiIiItliMUxEREREssVimIiIiIhki8UwEREREckWi2EiIiIiki0Ww0REREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2WIxTERERESyxWKYiIiIiGSLxTARERERyRaLYSIiIiKSLRbDRERERCRbLIaJiIiISLZYDBMRERGRbLEYJiIiIiLZYjFMRERERLLFYpiIiIiIZIvFMBERERHJloW5O0BERESA87pDJp9zZfPsdugJkbxwZJiIiIiIZIvFMBERERHJFothIiIiIpItzhkms+H8OCIiIjI3k0aGb9y4gcTERMycOROOjo7o1asXBg4ciOeeew4nT540eE5lZSWCg4Ph5OQEpVIJJycnBAcHo7Ky0uh19u3bBy8vL6hUKjg4OGDWrFkoLCw0Gq/RaBAQEID+/fvDysoKnp6e2L59OxobG015ekREREQkMyYVw2+99RaCgoJw+fJlzJgxA6+99homTZqEDz/8EN7e3njvvfd04qurq+Hr64uEhASMGDECQUFB8PDwQEJCAnx9fVFdXa13jU2bNmHhwoX4/vvvsXLlSgQEBCA/Px8+Pj7IycnRiy8pKcGECROQnp4Of39/rF27FgCwZs0arFy50pSnR0REREQyY9I0CS8vL+Tl5WHy5Mk67Z999hmmT5+OVatW4dlnn4VSqQQAxMfHo6ioCCEhIYiLi5PiIyMjER0djfj4eERFRUntGo0GkZGRcHd3R0FBAezt7QEAa9euhZeXFwIDA3H+/HlYWPy726tWrUJFRQUOHTqEWbNmAQA2btyIZ555BsnJyViwYAH8/PxMfFmIiIiISA5MGhn+7W9/q1cIA8DkyZPh5+eHf/3rXzhz5gwAQAiBlJQU2NjYICIiQic+NDQUDg4O2LVrF4QQUntqaioaGhoQFhYmFcIAMHLkSCxevBiXLl3C0aNHpfaLFy8iLy8Pfn5+UiEMAJaWloiJiQEAJCcnm/IUiYiIiEhG2mw1CUtLSwCQRm01Gg3Kysrg4+MDlUqlE9u7d29MmTIFN27cQGlpqdSunQYxc+ZMvcf39/cHAOTm5rYo3svLC3369NGJJyIiIiJqqk2K4WvXruHTTz/FwIEDMXr0aAD3imEAcHNzM3iOtl0bp/3cxsYGAwcObHG8sWsoFAq4urqirKwMNTU1rXlaRERERNTNPfTSavX19Vi0aBHq6uoQHx+Pnj17AgAqKioAQGe6Q1N2dnY6cdrPBwwYYFJ8S69hbW1tMKaurg51dXXS182tckFERERE3ctDjQw3NjbipZdeQl5eHlasWIFFixa1Vb86TGxsLOzt7aWPoUOHmrtLRERERNRBWl0MCyGwYsUKpKWl4fe//z127Nihc1w7Wtt0JLcp7Qhs01Fde3t7k+Nbcg3tCLEhoaGhqKiokD6uX79uNJaIiIiIupdWFcONjY1Yvnw53nnnHSxYsAC7d+9Gjx66D2Vojm9Thub7urm5oaqqCjdv3mxxvLFrCCFQWloKtVqtdwNfU0qlEnZ2djofRERERCQPJhfDjY2NCAwMRGpqKl544QW8++670jzhptzc3KBWq5Gfn6+3ucadO3eQl5cHtVoNV1dXqd3X1xcAkJWVpfd4mZmZOjEAMHXqVKPxBQUFKC8v14knIiIiImrKpGJYOyKcmpqK559/HmlpaQYLYeDeag6BgYGoqqpCdHS0zrHY2FjcunULgYGBUCgUUvuyZctgYWGBmJgYnakP586dw969e+Hi4oJp06ZJ7e7u7pgyZQqys7Nx+PBhqb2+vh7h4eEAgBUrVpjyFImI2l1ZWRkAYO7cudzanojIzBSi6a4XD7BhwwZERUXBxsYGf/zjH3V2gtOaO3cuxo4dC+DedsyTJk1CUVERZsyYgXHjxqG4uBgZGRkYO3Ysjh07pjeFISYmBuHh4XB0dMT8+fNRXV2N/fv3o7a2FpmZmXq7yZWUlMDb2xu1tbUICAiAWq3GkSNHcPr0aQQGBpq86UZlZaU0d7m9p0w4rzvUro/fHV3ZPNvcXSB6aEFBQUhMTMSwYcPg5+eHAQMGQKPRID09HUII7N+/HwEBAVL8/bn0V7/6FYqLi3HkyBGjuXTTpk0ICwuTcmlVVRUOHDiAO3fuIDMzU/rPmpY2l9bU1CAgIACDBw9GRkYGzpw5gxUrVuDtt99u8fNjHu04zIkkV22ZZ0wqhpcuXYo9e/Y0G5OamoqlS5dKX1dUVCAqKgrvv/8+bt68iYEDB2L+/PmIjIw0uiTa3/72NyQmJuLcuXPo1asXnnrqKURHR2PChAkG4y9evIiwsDBkZ2ejqqoKrq6ueOWVV7B69Wq9ucwPwiTeuTHxU3eQlpaGRYsW6eUZ7db2tra2KCsrk7a2125hb2xr+4iICL2t7T08PDB8+HCdre3PnTsHLy8vDBo0SG9re19fX+Tl5elsbV9fX49nnnkG//znP3H06NEWb23PPNpxmBNJrsxWDMsBk3jnxsRP3UFzecbf3x9ZWVn44osvMH78eAghMGTIEFRWVuLmzZs6I8B37tyBWq2GtbU1rl+/Lk07W79+PWJjY7Fnzx4sXrxY5/FXrVqFHTt2IDMzU9q98+LFixgxYgT8/Px0trwHgJMnT+LJJ5/EggULsG/fvod+fm1N7nmUOZHkqi3zTJttx0xERA+PW9sTEXUsFsNERJ0Et7YnIup4D70dMxERPbyuvLU9t7Unoq6MI8NERGbW1be257b2RNSVsRgmIjKj7rC1Pbe1J6KujMUwEZGZdJet7bmtPRF1ZSyGiYjMZM2aNdzanojIzFgMExF1MO32xmlpadzanojIzLiaBBFRB9PuImdjYwN3d3ds3LhRL6bp1vYhISH46KOPEB8fj1OnTultbR8SEqJzrru7OzZs2IDw8HB4enrqbG1fX1+P5ORknd3nACApKQne3t6YN2+ewa3tW7r7HBFRV8NimIiog127dg0AUFVVhZiYGIMxzs7OUjGsUqmQk5MjbW2fk5ODgQMHIigoCJGRkQbn8oaFhcHZ2RmJiYlISkpCr1694O3tbXRrew8PDxQUFCAsLAwZGRnS1vbbtm3D6tWr2+7JExF1MtyO+T7cRrRz49aj1B10ZJ4xB+bRjsOcSHLF7ZiJiIiIiNoAi2EiIiIiki0Ww0REREQkW7yBjrqU1swP5Jw6IiIiMoYjw0REREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2eINdERERF0UbyomengcGSYiIiIi2WIxTERERESyxWKYiIiIiGSLxTARERERyRaLYSIiIiKSLRbDRERERCRbLIaJiIiISLZYDBMRERGRbLEYJiIiIiLZYjFMRERERLLF7ZjbSGu2xCQiIiIi8+LIMBERERHJFothIiIiIpItTpOgbs/UKSxXNs9up54QERFRZ8ORYSIiIiKSLRbDRERERCRbLIaJiIiISLY4Z5iIiEhGWrMUKO+loO6MI8NEREREJFsshomIiIhItlgMExEREZFssRgmIiIiItniDXRERNQptObGLiKih8WRYSIiIiKSLRbDRERERCRbnCZBdB+uwUlERCQfHBkmIiIiItniyDBRG+BoMhERUdfEkWEiIiIikq1uMzL8xRdfIDIyEsePH8cvv/yCkSNH4tVXX8Xvfvc7c3eNiKjLYC4lQ/jfL+rOukUxnJOTA39/f/Tq1Qsvvvgi7O3tcfDgQSxcuBBXrlzB+vXrzd1FIqJOj7mUiORIIYQQ5u7Ew2hoaMBjjz2Gb7/9FsePH8cTTzwBALh9+zaeeuopXLhwASUlJXBzc2vR41VWVsLe3h4VFRWws7NrcT+4WDyZiqMm8tXaPNOe2jKXMo8SwBxH7ast82iXHxk+evQoLl26hGXLlknJGwBsbW3x5z//GS+++CJSU1OxadMmM/aSSB//7UidCXMpEclVly+Gc3JyAAAzZ87UO6Zty83N7cguERF1Ocyl1NZM/YOff+yTuXT5Ylij0QCAwX/dOTg44JFHHpFiDKmrq0NdXZ30dUVFBYB7w++maKyrMSmeqDUcg/5h8jlno/zboSf0MLT5pTPNUnuYXMo8Sm2B+Y1M0ZZ5tMsXw9qka29vb/C4nZ0dvv32W6Pnx8bGIioqSq996NChbdNBIjOzTzR3D8iY27dvG81dHe1hcinzKJkL8xu1RR7t8sXwwwoNDUVwcLD0dWNjI/71r3+hX79+UCgUUntlZSWGDh2K69evd5obXroqvpZtg69j2zDH6yiEwO3bt6FWqzvkeu2tpXnUEL6PCeD7gP6tpe+FtsyjXb4Y1v41oB3VuJ/2bkNjlEollEqlTlufPn2MxtvZ2fEHtY3wtWwbfB3bRke/jp1lRFjrYXKpqXnUEL6PCeD7gP6tJe+FtsqjXX4HOu38NkNz2W7duoWffvqpxcuqERHJFXMpEclVly+GfX19AQBZWVl6x7Rt2hgiIjKMuZSI5KrLF8PTp0/H8OHDsW/fPhQVFUntt2/fxl/+8hdYWFhg6dKlD30dpVKJyMhIvX8Fkun4WrYNvo5tg6/jPR2VS+/H158Avg/o38zxXujyO9ABQHZ2Nvz9/aFUKrFgwQLY2dnh4MGD+Oabb7Bx40aEhYWZu4tERJ0ecykRyVG3KIYBoKCgAJGRkTh+/Dh++eUXjBw5Eq+++ioWLlxo7q4REXUZzKVEJDfdphgmIiIiIjJVl58zTERERETUWiyGiYiIiEi2WAy3wBdffIFZs2bBwcEBKpUKXl5e2Ldvn7m71encuHEDiYmJmDlzJhwdHdGrVy8MHDgQzz33HE6ePKkXv2HDBigUCoMfvXv3NsMz6DycnZ2NvjYrV67Ui6+srERwcDCcnJygVCrh5OSE4OBgae92Odq9e7fR11D7MX36dCme78eOxbwqH8xn8pOWloZXXnkF48ePh1KphEKhwO7du43Gt+Z7vm/fPnh5eUGlUsHBwQGzZs1CYWFhq/rb5Xega285OTnw9/dHr1698OKLL8Le3h4HDx7EwoULceXKFaxfv97cXew03nrrLcTFxcHFxQUzZszAgAEDoNFokJ6ejvT0dOzfvx8BAQF65y1ZsgTOzs46bRYWfGva29vj1Vdf1WsfP368ztfV1dXw9fVFUVERZsyYgQULFqC4uBgJCQnIzs7GsWPHoFKpOqjXncfYsWMRGRlp8Nj777+Pc+fOwd/fX+8Y34/tj3lVfpjP5CU8PBxXr17FI488gkGDBuHq1atGY1vzPd+0aRPCwsLg6OiIlStXoqqqCgcOHICPjw8yMzMxdepU0zosyKj6+nrh4uIilEql+Oqrr6T2yspKMXLkSGFhYSEuXrxoxh52Lv/zP/8j8vLy9Nrz8vKEpaWl6Nu3r7hz547UHhkZKQCI7OzsDuxl1+Dk5CScnJxaFBsRESEAiJCQEIPtERER7dDDrquurk7069dPWFhYiJs3b0rtfD92DOZV+WE+k59PPvlEXLlyRQghRGxsrAAgUlNTDcaa+j2/ePGisLCwEO7u7qK8vFxqP3v2rLC2thYuLi6ivr7epP6yGG5GZmamACCWLVumd+zAgQMCgAgNDTVDz7qemTNnCgDiiy++kNpYfBjX0l8ejY2NQq1WCxsbG1FVVaVzrLa2Vjg4OIjBgweLxsbGdupp16P92Z07d65OO9+PHYN5VX6Yz+StuWK4Nd/z0NBQAUDs2bNH7/FWrlwpAIjMzEyT+sj//TUjJycHADBz5ky9Y9q23NzcjuxSl2VpaQnA8L+bP/vsMxQUFKBnz5547LHH8Otf/5q7EAGoq6vDnj17cOPGDTg4OMDb2xtjxozRidFoNCgrK4O/v7/ev5F69+6NKVOm4MMPP0RpaSnc3Nw6svud1q5duwAAgYGBBo/z/di+mFflifmMDGnN97y5HOLv748dO3YgNzfX4HFjWAw3Q6PRAIDBHzoHBwc88sgjUgwZd+3aNXz66acYOHAgRo8erXc8IiJC5+tBgwZhz549mDFjRkd1sVO6efOm3va3Tz/9NN5991088sgjAJp/jzZt12g0/OUB4OrVq/jnP/+JwYMH4+mnnzYYw/dj+2JelSfmMzKkNd9zjUYDGxsbDBw4sNl4U3A1iWZUVFQAuDfx3xA7Ozsphgyrr6/HokWLUFdXh/j4ePTs2VM6NnbsWOzZswdXrlxBbW0tNBoN/vKXv6C8vBxz5sxBcXGxGXtuXi+99BJycnLw448/orKyEidOnMAzzzyDI0eOYM6cORD/t1dOS96jTePkLjU1FY2NjVi2bJnOexHg+7GjMK/KD/MZGdOa73lFRUWbv0c4MkztprGxES+99BLy8vKwYsUKLFq0SOf43Llzdb52dXVFeHg4Hn30Ubz88svYuHEj/vGPf3RgjzuP+0cnJ06ciI8//hi+vr44duwYDh8+jNmzZ5upd11TY2MjUlNToVAo8NJLL+kd5/uRqH0wn1Fnx5HhZmj/8jD2F0ZlZaXRv07kTgiBFStWIC0tDb///e+xY8eOFp+7ZMkSWFhYID8/vx172PX06NEDy5YtAwDptWnJe7RpnJx98sknuHbtGqZNm4Zhw4a1+Dy+H9sW8yoBzGd0T2u+5/b29m3+HmEx3Izm5p7cunULP/30E+ctGdDY2Ijly5fjnXfewYIFC7B792706NHyt1qvXr1ga2uLmpqaduxl16SdW6d9bR40P+pB87Hk5EE3zhnD92PbYl4lLeYzas333M3NDVVVVbh582aL4luCxXAzfH19AQBZWVl6x7Rt2hi6p7GxEYGBgUhNTcULL7yAd999V29u5oNoNBrcunVLb+MDgrSTn/a1cXNzg1qtRn5+Pqqrq3Vi79y5g7y8PKjVari6unZ0VzuVn3/+GR9++CH69u2LefPmmXQu349ti3mVtJjPqDXf8+ZySGZmpk5Mi5m0EJvM1NfXi+HDhwulUilOnToltTddHP7ChQvm62Anc/fuXbF06VIBQDz//PPNLnpdWVkpiouL9dr/9a9/icmTJwsAYvPmze3Z3U7r3Llz4tatW3rtn332mejdu7dQKpXi6tWrUjsXqX+whIQEAUCsXbvW4HG+HzsO86q8MJ9RW2+6ceHChTbfdEMhxP/dxkkGZWdnw9/fH0qlEgsWLICdnR0OHjyIb775Bhs3bkRYWJi5u9hpbNiwAVFRUbCxscEf//hHg2sKz507F2PHjsWVK1cwbNgwjB8/HqNHj8aAAQNw48YNZGRk4Oeff8aMGTPw8ccfo1evXmZ4Jua1YcMGxMfHY/r06XB2doZSqcTZs2eRlZWFHj16YMeOHTr/6q+ursakSZOkrSzHjRuH4uJiZGRkYOzYsdy+FMDo0aNx9uxZnD592uDyfnw/dizmVflgPpOnlJQUHDt2DABw5swZfPXVV/Dx8ZFGeOfOnSvdtNya73lMTAzCw8Ph6OiI+fPno7q6Gvv370dtbS0yMzPh5+dnWodNKp1l6uTJk+Lpp58W9vb2wsrKSowfP16kpaWZu1udzpIlSwSAZj+0fxlWVFSI1atXi3HjxolHHnlEWFhYCHt7ezFp0iSxY8cO0dDQYN4nY0Y5OTkiICBAuLq6CltbW2FpaSmGDBkiXnzxRXHy5EmD55SXl4ugoCAxdOhQYWlpKYYOHSqCgoJ0/mqWq5MnTwoAwsvLy2gM348dj3lVHpjP5OlB9UBkZKROfGu+52lpaWL8+PHCyspK2Nvbi6effloUFBS0qr8cGSYiIiIi2eINdEREREQkWyyGiYiIiEi2WAwTERERkWyxGCYiIiIi2WIxTERERESyxWKYiIiIiGSLxTARERERyRaLYSIiIiKSLRbDRERERCRbLIaJiIiISLZYDBMRERGRbLEYJiIiIiLZYjFMRERERLL1/wHFi2CRKsABegAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)[\"src\"] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)[\"trg\"] for x in train_data.examples])\n",
    "\n",
    "print(\"Length distribution in Train data\")\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key=_len_sort_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 256]\n",
      "\t[.trg]:[torch.LongTensor of size 48x256]\n",
      "\t[.src]:[torch.LongTensor of size 47x256]\n",
      "torch.Size([47, 256]) torch.Size([48, 256])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 6\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "MAX_LEN = 1000\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, ENC_DROPOUT, MAX_LEN)\n",
    "dec = Decoder(\n",
    "    OUTPUT_DIM, DEC_EMB_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, DEC_DROPOUT, MAX_LEN\n",
    ")\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9249, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.5, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6720, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (out): Linear(in_features=256, out_features=6720, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (self_attn1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (self_attn2): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.5, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12,212,288 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi[\"<pad>\"]\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = my_network.CosineWarmupScheduler(\n",
    "    optimizer=optimizer, warmup=100, max_iters=2000\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # output = [trg sent len, batch size, output dim]\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        # trg = [(trg sent len - 1) * batch size]\n",
    "        # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i + 1) % 10 == 0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label=\"train loss\")\n",
    "            ax[0].set_xlabel(\"Batch\")\n",
    "            ax[0].set_title(\"Train loss\")\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label=\"general train history\")\n",
    "                ax[1].set_xlabel(\"Epoch\")\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label=\"general valid history\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # trg = [(trg sent len - 1) * batch size]\n",
    "            # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trg \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtrg\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m model(src, trg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# trg = [trg sent len, batch size]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# output = [trg sent len, batch size, output dim]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m output \u001b[39m=\u001b[39m output[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:187\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_len):\n\u001b[1;32m    182\u001b[0m     trg_mask \u001b[39m=\u001b[39m (\n\u001b[1;32m    183\u001b[0m         torch\u001b[39m.\u001b[39mtril(torch\u001b[39m.\u001b[39mones(t, t))\n\u001b[1;32m    184\u001b[0m         \u001b[39m.\u001b[39mexpand(batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mnum_heads, t, t)\n\u001b[1;32m    185\u001b[0m         \u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\u001b[39minput\u001b[39;49m, enc_out, trg_mask)\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m max_len \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    189\u001b[0m         outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    190\u001b[0m             (nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(sos, trg_vocab_size), outputs), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    191\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:152\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, enc_out, mask)\u001b[0m\n\u001b[1;32m    150\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(x)\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 152\u001b[0m     x \u001b[39m=\u001b[39m l(x, enc_out, mask)\n\u001b[1;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:107\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, enc_output, mask)\u001b[0m\n\u001b[1;32m    105\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm2(x)\n\u001b[1;32m    106\u001b[0m attn_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn2(x, enc_output, enc_output)\n\u001b[0;32m--> 107\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(attn_out)\n\u001b[1;32m    109\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm3(x)\n\u001b[1;32m    110\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed_forward(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(\n",
    "        model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history\n",
    "    )\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"transformer-model.pt\")\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: there is a 24 - hour front desk at the property .\n",
      "Generated: the property offers a 24 - hour front desk . .\n",
      "\n",
      "Original: this property also features free wifi .\n",
      "Generated: free wifi access . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1, 2]:\n",
    "    src = batch.src[:, idx : idx + 1]\n",
    "    trg = batch.trg[:, idx : idx + 1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:03, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.load_state_dict(torch.load(\"transformer-model.pt\"))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0)  # turn off teacher forcing\n",
    "\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "\n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend(\n",
    "            [get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T]\n",
    "        )\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.139920232081806"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
