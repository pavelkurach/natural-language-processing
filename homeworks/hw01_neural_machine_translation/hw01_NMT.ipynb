{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab assignment 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "\n",
    "path_do_data = \"../../datasets/Machine_translation_EN_RU/data.txt\"\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = \"./data.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({\"figure.figsize\": (16, 12), \"font.size\": 14})\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data, format=\"tsv\", fields=[(\"trg\", TRG), (\"src\", SRC)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=3)\n",
    "TRG.build_vocab(train_data, min_freq=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9216\n",
      "Unique tokens in target (en) vocabulary: 6677\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'песчаного',\n",
       " 'ферме',\n",
       " 'крепость',\n",
       " '87',\n",
       " 'электронную',\n",
       " 'pace',\n",
       " 'форталеза',\n",
       " 'доставят',\n",
       " 'транспортных']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'gourmet', 'california', 'desserts', 'money', 'soho', 'marne']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['the', 'ski', 'bus', 'stop', 'is', 'located', '50', 'metres', 'from', 'the', 'property', 'and', 'the', 'hahnenkamm', 'sku', 'lift', 'is', 'a', '5', '-', 'minute', 'drive', 'away', '.'], 'src': ['бесплатный', 'лыжный', 'автобус', 'останавливается', 'в', '50', 'метрах', 'от', 'апартаментов', '.', 'до', 'горнолыжного', 'подъемника', 'ханненкамм', 'можно', 'доехать', 'за', '5', 'минут', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)[\"src\"] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)[\"trg\"] for x in train_data.examples])\n",
    "\n",
    "print(\"Length distribution in Train data\")\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \n",
    "                      \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key=_len_sort_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 256]\n",
      "\t[.trg]:[torch.LongTensor of size 47x256]\n",
      "\t[.src]:[torch.LongTensor of size 56x256]\n",
      "torch.Size([56, 256]) torch.Size([47, 256])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 6\n",
    "ENC_DROPOUT = 0.3\n",
    "DEC_DROPOUT = 0.3\n",
    "MAX_LEN = 1000\n",
    "\n",
    "PAD_IDX = TRG.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, ENC_DROPOUT, MAX_LEN)\n",
    "dec = Decoder(\n",
    "    OUTPUT_DIM, DEC_EMB_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, DEC_DROPOUT, MAX_LEN\n",
    ")\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device, src_pad_idx).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9216, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6677, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (out): Linear(in_features=256, out_features=6677, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (self_attn1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (self_attn2): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for layer in m._modules:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12,115,989 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = my_network.CosineWarmupScheduler(\n",
    "    optimizer=optimizer, warmup=200, max_iters=3000\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None, epoch=1\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg, 0.5 / epoch)\n",
    "\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # output = [trg sent len, batch size, output dim]\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        # trg = [(trg sent len - 1) * batch size]\n",
    "        # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i + 1) % 10 == 0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label=\"train loss\")\n",
    "            ax[0].set_xlabel(\"Batch\")\n",
    "            ax[0].set_title(\"Train loss\")\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label=\"general train history\")\n",
    "                ax[1].set_xlabel(\"Epoch\")\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label=\"general valid history\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # trg = [(trg sent len - 1) * batch size]\n",
    "            # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, N_EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history, epoch\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trg \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtrg\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m model(src, trg, \u001b[39m0.5\u001b[39;49m \u001b[39m/\u001b[39;49m epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# trg = [trg sent len, batch size]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# output = [trg sent len, batch size, output dim]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y141sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m output \u001b[39m=\u001b[39m output[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:189\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_len):\n\u001b[1;32m    184\u001b[0m     trg_mask \u001b[39m=\u001b[39m (\n\u001b[1;32m    185\u001b[0m         torch\u001b[39m.\u001b[39mtril(torch\u001b[39m.\u001b[39mones(t, t))\n\u001b[1;32m    186\u001b[0m         \u001b[39m.\u001b[39mexpand(batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mnum_heads, t, t)\n\u001b[1;32m    187\u001b[0m         \u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    188\u001b[0m     )\n\u001b[0;32m--> 189\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\u001b[39minput\u001b[39;49m, enc_out, trg_mask)\n\u001b[1;32m    190\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m max_len \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    191\u001b[0m         outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    192\u001b[0m             (nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(sos, trg_vocab_size), outputs), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    193\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:153\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, enc_out, mask)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m    152\u001b[0m     x \u001b[39m=\u001b[39m l(x, enc_out, mask)\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39;49mnorm(\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m) \u001b[39m-\u001b[39;49m x\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m    155\u001b[0m ))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/functional.py:1481\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnorm\u001b[39m(\u001b[39minput\u001b[39m, p: Optional[Union[\u001b[39mfloat\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfro\u001b[39m\u001b[39m\"\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdim\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns the matrix norm or vector norm of a given tensor.\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m \n\u001b[1;32m   1390\u001b[0m \u001b[39m    .. warning::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[39m        (tensor(3.7417), tensor(11.2250))\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39minput\u001b[39;49m):\n\u001b[1;32m   1482\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1483\u001b[0m             norm, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, p\u001b[39m=\u001b[39mp, dim\u001b[39m=\u001b[39mdim, keepdim\u001b[39m=\u001b[39mkeepdim, out\u001b[39m=\u001b[39mout, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m   1485\u001b[0m     \u001b[39m# NB. All the repeated code and weird python is to please TorchScript.\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m     \u001b[39m#     For a more compact implementation see the relevant function in `_refs/__init__.py`\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \n\u001b[1;32m   1488\u001b[0m     \u001b[39m# We don't do this for MPS or sparse tensors\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(\n",
    "        model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history, epoch\n",
    "    )\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"transformer-model.pt\")\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/qd_50t6125vb7v8pbdy0x1rh0000gn/T/ipykernel_69520/4092573867.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import imp\n",
    "\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = batch.src\n",
    "trg = batch.trg\n",
    "trg[0, :].unsqueeze(0)[:, 1:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Decoder' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 40\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y146sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m src \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39msrc[:, idx : idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y146sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trg \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtrg[:, idx : idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#Y146sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m generate_translation(src, trg, model, TRG\u001b[39m.\u001b[39;49mvocab)\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/utils.py:25\u001b[0m, in \u001b[0;36mgenerate_translation\u001b[0;34m(src, trg, model, TRG_vocab)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_translation\u001b[39m(src, trg, model, TRG_vocab):\n\u001b[1;32m     23\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 25\u001b[0m     output \u001b[39m=\u001b[39m model(src, trg, \u001b[39m0\u001b[39;49m)  \u001b[39m# turn off teacher forcing\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     28\u001b[0m     original \u001b[39m=\u001b[39m get_text(\u001b[39mlist\u001b[39m(trg[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()), TRG_vocab)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:187\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_len):\n\u001b[1;32m    182\u001b[0m     trg_mask \u001b[39m=\u001b[39m (\n\u001b[1;32m    183\u001b[0m         torch\u001b[39m.\u001b[39mtril(torch\u001b[39m.\u001b[39mones(t, t))\n\u001b[1;32m    184\u001b[0m         \u001b[39m.\u001b[39mexpand(batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mnum_heads, t, t)\n\u001b[1;32m    185\u001b[0m         \u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\u001b[39minput\u001b[39;49m, enc_out, trg_mask)\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m max_len \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    189\u001b[0m         outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    190\u001b[0m             (nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(sos, trg_vocab_size), outputs), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    191\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:153\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, enc_out, mask)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m    152\u001b[0m     x \u001b[39m=\u001b[39m l(x, enc_out, mask)\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Decoder' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "for idx in [1, 2]:\n",
    "    src = batch.src[:, idx : idx + 1]\n",
    "    trg = batch.trg[:, idx : idx + 1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:03, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.load_state_dict(torch.load(\"transformer-model.pt\"))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0)  # turn off teacher forcing\n",
    "\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "\n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend(\n",
    "            [get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T]\n",
    "        )\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.139920232081806"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
