{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab assignment 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9267\n",
      "Unique tokens in target (en) vocabulary: 6727\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'проходят',\n",
       " 'saint',\n",
       " 'игрой',\n",
       " '73',\n",
       " 'ялты',\n",
       " 'familia',\n",
       " 'телевизионный',\n",
       " 'двухэтажные',\n",
       " 'таррагона']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'cafe', 'es', 'asakusa', 'martins', 'refugio', 'maintains']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['a', 'continental', 'or', 'full', 'english', 'breakfast', 'is', 'served', 'every', 'morning', 'for', 'a', 'supplement', 'at', 'domaine', 'de', 'piscia', '.'], 'src': ['каждое', 'утро', 'в', 'отеле', 'domaine', 'de', 'piscia', 'за', 'дополнительную', 'плату', 'сервируют', 'континентальный', 'или', 'полный', 'английский', 'завтрак', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.trg]:[torch.LongTensor of size 44x128]\n",
      "\t[.src]:[torch.LongTensor of size 45x128]\n",
      "torch.Size([45, 128]) torch.Size([44, 128])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "MAX_LEN = 1000\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, ENC_DROPOUT, MAX_LEN)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, DEC_DROPOUT, MAX_LEN)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9267, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x EncoderBlock(\n",
       "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.5, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6727, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (out): Linear(in_features=256, out_features=6727, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x DecoderBlock(\n",
       "        (query1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (query2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (self_attn1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (self_attn2): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.5, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,183,815 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m trg \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtrg\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m output \u001b[39m=\u001b[39m model(src, trg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#trg = [trg sent len, batch size]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#output = [trg sent len, batch size, output dim]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m output \u001b[39m=\u001b[39m output[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:214\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_len):\n\u001b[1;32m    209\u001b[0m     trg_mask \u001b[39m=\u001b[39m (\n\u001b[1;32m    210\u001b[0m         torch\u001b[39m.\u001b[39mtril(torch\u001b[39m.\u001b[39mones(t, t))\n\u001b[1;32m    211\u001b[0m         \u001b[39m.\u001b[39mexpand(batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mnum_heads, t, t)\n\u001b[1;32m    212\u001b[0m         \u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    213\u001b[0m     )\n\u001b[0;32m--> 214\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\u001b[39minput\u001b[39;49m, enc_out, trg_mask)\n\u001b[1;32m    215\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m max_len \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    216\u001b[0m         outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    217\u001b[0m             (nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(sos, trg_vocab_size), outputs), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    218\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:179\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, enc_out, mask)\u001b[0m\n\u001b[1;32m    177\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(x)\n\u001b[1;32m    178\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 179\u001b[0m     x \u001b[39m=\u001b[39m l(x, enc_out, mask)\n\u001b[1;32m    180\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:134\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, enc_output, mask)\u001b[0m\n\u001b[1;32m    128\u001b[0m attn_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn2(\n\u001b[1;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery2(x),\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey2(enc_output),\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue2(enc_output),\n\u001b[1;32m    132\u001b[0m )\n\u001b[1;32m    133\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attn_out)\n\u001b[0;32m--> 134\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm2(x)\n\u001b[1;32m    136\u001b[0m feed_forward_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed_forward(x)\n\u001b[1;32m    137\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(feed_forward_out)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[1;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: there is a 24 - hour front desk at the property .\n",
      "Generated: the property offers a 24 - hour front desk . .\n",
      "\n",
      "Original: this property also features free wifi .\n",
      "Generated: free wifi access . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:03, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.139920232081806"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
