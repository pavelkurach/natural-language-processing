{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab assignment 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9266\n",
      "Unique tokens in target (en) vocabulary: 6737\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'доставки',\n",
       " 'hills',\n",
       " 'музыка',\n",
       " 'bed',\n",
       " 'эн',\n",
       " 'medical',\n",
       " 'тяньхэ',\n",
       " 'диагональю',\n",
       " 'странд']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'cafe', 'lessons', 'duplex', 'lemon', 'scene', 'mariupol']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['complimentary', 'coffee', 'is', 'served', 'in', 'the', 'lobby', '.'], 'src': ['в', 'лобби', 'подается', 'бесплатный', 'кофе', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.trg]:[torch.LongTensor of size 55x128]\n",
      "\t[.src]:[torch.LongTensor of size 55x128]\n",
      "torch.Size([55, 128]) torch.Size([55, 128])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 6\n",
    "ENC_DROPOUT = 0.2\n",
    "DEC_DROPOUT = 0.2\n",
    "MAX_LEN = 1000\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, ENC_DROPOUT, MAX_LEN)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_EMB_DIM, N_HEADS, N_LAYERS, DEC_DROPOUT, MAX_LEN)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9266, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.2, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6737, 256)\n",
       "    (pos_enc): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (out): Linear(in_features=256, out_features=6737, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (query1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (query2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (self_attn1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (self_attn2): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.2, inplace=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,778,129 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = my_network.CosineWarmupScheduler(optimizer=optimizer, warmup=100, max_iters=3200)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.999997258443473e-06]\n",
      "[1.9999978067553793e-05]\n",
      "[2.9999925978027876e-05]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m trg \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtrg\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m output \u001b[39m=\u001b[39m model(src, trg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#trg = [trg sent len, batch size]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#output = [trg sent len, batch size, output dim]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pavelkurach/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/hw01_NMT.ipynb#X46sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m output \u001b[39m=\u001b[39m output[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:216\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_len):\n\u001b[1;32m    211\u001b[0m     trg_mask \u001b[39m=\u001b[39m (\n\u001b[1;32m    212\u001b[0m         torch\u001b[39m.\u001b[39mtril(torch\u001b[39m.\u001b[39mones(t, t))\n\u001b[1;32m    213\u001b[0m         \u001b[39m.\u001b[39mexpand(batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mnum_heads, t, t)\n\u001b[1;32m    214\u001b[0m         \u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    215\u001b[0m     )\n\u001b[0;32m--> 216\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\u001b[39minput\u001b[39;49m, enc_out, trg_mask)\n\u001b[1;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m max_len \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    218\u001b[0m         outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    219\u001b[0m             (nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(sos, trg_vocab_size), outputs), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    220\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:181\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, enc_out, mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(x)\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 181\u001b[0m     x \u001b[39m=\u001b[39m l(x, enc_out, mask)\n\u001b[1;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/natural-language-processing/homeworks/hw01_neural_machine_translation/my_network.py:130\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, enc_output, mask)\u001b[0m\n\u001b[1;32m    127\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attn_out)\n\u001b[1;32m    128\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x)\n\u001b[0;32m--> 130\u001b[0m attn_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn2(\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery2(x),\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey2(enc_output),\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue2(enc_output),\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attn_out)\n\u001b[1;32m    136\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/functional.py:5346\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5343\u001b[0m attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(attn_output_weights, v)\n\u001b[1;32m   5345\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(tgt_len \u001b[39m*\u001b[39m bsz, embed_dim)\n\u001b[0;32m-> 5346\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n\u001b[1;32m   5347\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mview(tgt_len, bsz, attn_output\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[1;32m   5349\u001b[0m \u001b[39m# optionally average attention weights over heads\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer-model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: there is a 24 - hour front desk at the property .\n",
      "Generated: the property offers a 24 - hour front desk . .\n",
      "\n",
      "Original: this property also features free wifi .\n",
      "Generated: free wifi access . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:03, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.139920232081806"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
